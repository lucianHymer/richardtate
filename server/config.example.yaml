# Server configuration
server:
  # HTTP server bind address (use "localhost:8080" for local only, "0.0.0.0:8080" for LAN access)
  bind_address: "localhost:8080"

  # Log level: debug, info, warn, error, fatal
  log_level: "info"

  # Log format: text or json
  log_format: "text"

# WebRTC configuration
webrtc:
  # ICE servers for connection establishment
  # For localhost testing, this can be empty
  # For LAN/remote clients, configure STUN/TURN servers
  ice_servers: []
  # Example:
  # ice_servers:
  #   - urls: ["stun:stun.l.google.com:19302"]

# Transcription configuration
transcription:
  # Whisper model path (relative to server binary or absolute)
  # Download with: ./scripts/download-models.sh
  model_path: "./models/ggml-large-v3-turbo.bin"

  # Language code (e.g., "en", "es", "fr") or empty for auto-detect
  language: ""

  # Number of CPU threads for transcription (0 = auto-detect)
  # Higher values = faster transcription but more CPU usage
  threads: 0

  # Save audio chunks as WAV files to /tmp/chunk-*.wav for debugging
  enable_debug_wav: false

# Noise suppression (RNNoise)
# NOTE: RNNoise is controlled by the build tag, not a config flag
# - Build WITH RNNoise: go build -tags rnnoise ...
# - Build WITHOUT RNNoise: go build ... (uses pass-through, no denoising)
# See: ./scripts/build-mac.sh for automatic build with RNNoise detection
noise_suppression:
  # Path to RNNoise model file (only used when built with -tags rnnoise)
  # Download with: ./scripts/download-rnnoise.sh
  model_path: "./models/rnnoise/lq.rnnn"

# Voice Activity Detection (VAD)
# VAD is always enabled - these settings control its behavior
vad:
  # Energy threshold for speech detection (higher = requires louder speech)
  # Typical values: 50-200 for normal mic, 200-500 for noisy environment
  # Too low: false positives from background noise
  # Too high: misses quiet speech
  energy_threshold: 100.0

  # Silence duration (ms) to trigger transcription
  # Audio chunks are sent to Whisper after this much continuous silence
  # Lower = faster response, but may cut off mid-sentence
  # Higher = more complete sentences, but slower response
  silence_threshold_ms: 1000

  # Minimum chunk duration (ms) before sending to Whisper
  # Prevents very short chunks that waste processing time
  min_chunk_duration_ms: 500

  # Maximum chunk duration (ms) - safety limit
  # Prevents unbounded memory usage if user talks continuously
  max_chunk_duration_ms: 30000
